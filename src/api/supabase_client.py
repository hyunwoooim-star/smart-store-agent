"""
supabase_client.py - Supabase ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ (v3.1)

ê¸°ëŠ¥:
1. ë¶„ì„ ê²°ê³¼ ì €ì¥
2. í‚¤ì›Œë“œ ë°ì´í„° ì €ì¥/ì¡°íšŒ
3. ë¦¬í¬íŠ¸ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
"""

import os
from datetime import datetime
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, asdict

# Supabase í´ë¼ì´ì–¸íŠ¸ (ì„¤ì¹˜ í•„ìš”: pip install supabase)
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    Client = None


@dataclass
class KeywordRecord:
    """í‚¤ì›Œë“œ ë ˆì½”ë“œ"""
    keyword: str
    monthly_search_volume: int
    total_products: int
    competition_rate: float
    opportunity_score: float
    category: Optional[str] = None
    created_at: Optional[str] = None


@dataclass
class AnalysisRecord:
    """ë¶„ì„ ê²°ê³¼ ë ˆì½”ë“œ"""
    report_id: str
    product_name: str
    category: str
    margin_percent: float
    total_score: float
    is_viable: bool
    recommendation: str
    created_at: Optional[str] = None
    raw_data: Optional[Dict] = None


class SupabaseClient:
    """Supabase í´ë¼ì´ì–¸íŠ¸ (v3.5.2 - ìºì‹± ë ˆì´ì–´ ì¶”ê°€)"""

    # í…Œì´ë¸”ëª…
    TABLE_KEYWORDS = "keywords"
    TABLE_ANALYSES = "analyses"
    TABLE_REPORTS = "reports"
    TABLE_SCRAPE_CACHE = "scrape_cache"  # Phase 5.2 ìºì‹± í…Œì´ë¸”

    # ìºì‹œ ìœ íš¨ ê¸°ê°„ (ì¼)
    CACHE_TTL_DAYS_1688 = 3     # 1688 ìƒí’ˆ ì •ë³´: 3ì¼
    CACHE_TTL_DAYS_REVIEW = 7   # ë¦¬ë·° ë¶„ì„: 7ì¼

    def __init__(self, url: str = None, key: str = None):
        """
        Args:
            url: Supabase URL (í™˜ê²½ë³€ìˆ˜ SUPABASE_URL)
            key: Supabase API Key (í™˜ê²½ë³€ìˆ˜ SUPABASE_KEY)
        """
        self.url = url or os.getenv("SUPABASE_URL", "")
        self.key = key or os.getenv("SUPABASE_KEY", "")
        self.client: Optional[Client] = None
        self._initialized = False

    def initialize(self) -> bool:
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not SUPABASE_AVAILABLE:
            print("âš ï¸ supabase íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install supabase")
            return False

        if not self.url or not self.key:
            print("âš ï¸ SUPABASE_URL ë˜ëŠ” SUPABASE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False

        try:
            self.client = create_client(self.url, self.key)
            self._initialized = True
            return True
        except Exception as e:
            print(f"âš ï¸ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    def is_connected(self) -> bool:
        """ì—°ê²° ìƒíƒœ í™•ì¸"""
        return self._initialized and self.client is not None

    # --- í‚¤ì›Œë“œ ê´€ë ¨ ---

    def save_keywords(self, keywords: List[KeywordRecord]) -> bool:
        """í‚¤ì›Œë“œ ì €ì¥"""
        if not self.is_connected():
            return False

        try:
            data = []
            for kw in keywords:
                record = asdict(kw)
                record["created_at"] = datetime.now().isoformat()
                data.append(record)

            self.client.table(self.TABLE_KEYWORDS).insert(data).execute()
            return True
        except Exception as e:
            print(f"í‚¤ì›Œë“œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def get_keywords(self, category: str = None, limit: int = 100) -> List[Dict]:
        """í‚¤ì›Œë“œ ì¡°íšŒ"""
        if not self.is_connected():
            return []

        try:
            query = self.client.table(self.TABLE_KEYWORDS).select("*")

            if category:
                query = query.eq("category", category)

            query = query.order("opportunity_score", desc=True).limit(limit)
            result = query.execute()

            return result.data if result.data else []
        except Exception as e:
            print(f"í‚¤ì›Œë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def search_keywords(self, search_term: str, limit: int = 20) -> List[Dict]:
        """í‚¤ì›Œë“œ ê²€ìƒ‰"""
        if not self.is_connected():
            return []

        try:
            result = (
                self.client.table(self.TABLE_KEYWORDS)
                .select("*")
                .ilike("keyword", f"%{search_term}%")
                .order("opportunity_score", desc=True)
                .limit(limit)
                .execute()
            )
            return result.data if result.data else []
        except Exception as e:
            print(f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    # --- ë¶„ì„ ê²°ê³¼ ê´€ë ¨ ---

    def save_analysis(self, analysis: AnalysisRecord) -> bool:
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        if not self.is_connected():
            return False

        try:
            record = asdict(analysis)
            record["created_at"] = datetime.now().isoformat()

            self.client.table(self.TABLE_ANALYSES).insert(record).execute()
            return True
        except Exception as e:
            print(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def get_analyses(self, product_name: str = None, limit: int = 50) -> List[Dict]:
        """ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        if not self.is_connected():
            return []

        try:
            query = self.client.table(self.TABLE_ANALYSES).select("*")

            if product_name:
                query = query.ilike("product_name", f"%{product_name}%")

            query = query.order("created_at", desc=True).limit(limit)
            result = query.execute()

            return result.data if result.data else []
        except Exception as e:
            print(f"ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_analysis_by_id(self, report_id: str) -> Optional[Dict]:
        """IDë¡œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        if not self.is_connected():
            return None

        try:
            result = (
                self.client.table(self.TABLE_ANALYSES)
                .select("*")
                .eq("report_id", report_id)
                .single()
                .execute()
            )
            return result.data
        except Exception as e:
            print(f"ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    # --- ë¦¬í¬íŠ¸ ê´€ë ¨ ---

    def save_report(self, report_id: str, content: str, format: str = "markdown") -> bool:
        """ë¦¬í¬íŠ¸ ì €ì¥"""
        if not self.is_connected():
            return False

        try:
            record = {
                "report_id": report_id,
                "content": content,
                "format": format,
                "created_at": datetime.now().isoformat()
            }

            self.client.table(self.TABLE_REPORTS).insert(record).execute()
            return True
        except Exception as e:
            print(f"ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def get_report(self, report_id: str) -> Optional[str]:
        """ë¦¬í¬íŠ¸ ì¡°íšŒ"""
        if not self.is_connected():
            return None

        try:
            result = (
                self.client.table(self.TABLE_REPORTS)
                .select("content")
                .eq("report_id", report_id)
                .single()
                .execute()
            )
            return result.data.get("content") if result.data else None
        except Exception as e:
            print(f"ë¦¬í¬íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    # --- ìºì‹± ë ˆì´ì–´ (Phase 5.2 - Gemini CTO ì¡°ì–¸) ---

    def get_cached_scrape(self, url: str) -> Optional[Dict]:
        """ìºì‹œëœ ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ì¡°íšŒ

        Args:
            url: 1688 ìƒí’ˆ URL

        Returns:
            ìºì‹œëœ ë°ì´í„° (ìˆê³  ìœ íš¨í•˜ë©´) / None (ì—†ê±°ë‚˜ ë§Œë£Œ)
        """
        if not self.is_connected():
            return None

        try:
            from datetime import datetime, timedelta

            # URL ì •ê·œí™” (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°)
            normalized_url = self._normalize_url(url)

            result = (
                self.client.table(self.TABLE_SCRAPE_CACHE)
                .select("*")
                .eq("url", normalized_url)
                .single()
                .execute()
            )

            if not result.data:
                return None

            # TTL ì²´í¬
            created_at = datetime.fromisoformat(result.data["created_at"].replace("Z", "+00:00"))
            ttl_days = self.CACHE_TTL_DAYS_1688
            if datetime.now(created_at.tzinfo) - created_at > timedelta(days=ttl_days):
                # ìºì‹œ ë§Œë£Œ - ì‚­ì œ
                self.client.table(self.TABLE_SCRAPE_CACHE).delete().eq("url", normalized_url).execute()
                return None

            print(f"âœ… [Cache Hit] {normalized_url[:50]}...")
            return result.data.get("data")

        except Exception as e:
            # ìºì‹œ ë¯¸ìŠ¤ëŠ” ì •ìƒ ë™ì‘
            return None

    def save_scrape_cache(self, url: str, data: Dict) -> bool:
        """ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ìºì‹œ ì €ì¥

        Args:
            url: 1688 ìƒí’ˆ URL
            data: ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ë°ì´í„°

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        if not self.is_connected():
            return False

        try:
            normalized_url = self._normalize_url(url)

            record = {
                "url": normalized_url,
                "data": data,
                "created_at": datetime.now().isoformat()
            }

            # Upsert (ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì‚½ì…)
            self.client.table(self.TABLE_SCRAPE_CACHE).upsert(
                record, on_conflict="url"
            ).execute()

            print(f"ğŸ’¾ [Cache Save] {normalized_url[:50]}...")
            return True

        except Exception as e:
            print(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def get_cached_review(self, product_name: str, category: str) -> Optional[Dict]:
        """ìºì‹œëœ ë¦¬ë·° ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        if not self.is_connected():
            return None

        try:
            from datetime import datetime, timedelta

            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"review:{category}:{product_name[:50]}"

            result = (
                self.client.table(self.TABLE_SCRAPE_CACHE)
                .select("*")
                .eq("url", cache_key)
                .single()
                .execute()
            )

            if not result.data:
                return None

            # TTL ì²´í¬ (ë¦¬ë·°ëŠ” 7ì¼)
            created_at = datetime.fromisoformat(result.data["created_at"].replace("Z", "+00:00"))
            if datetime.now(created_at.tzinfo) - created_at > timedelta(days=self.CACHE_TTL_DAYS_REVIEW):
                self.client.table(self.TABLE_SCRAPE_CACHE).delete().eq("url", cache_key).execute()
                return None

            print(f"âœ… [Review Cache Hit] {cache_key[:30]}...")
            return result.data.get("data")

        except Exception:
            return None

    def save_review_cache(self, product_name: str, category: str, data: Dict) -> bool:
        """ë¦¬ë·° ë¶„ì„ ê²°ê³¼ ìºì‹œ ì €ì¥"""
        if not self.is_connected():
            return False

        try:
            cache_key = f"review:{category}:{product_name[:50]}"

            record = {
                "url": cache_key,
                "data": data,
                "created_at": datetime.now().isoformat()
            }

            self.client.table(self.TABLE_SCRAPE_CACHE).upsert(
                record, on_conflict="url"
            ).execute()

            print(f"ğŸ’¾ [Review Cache Save] {cache_key[:30]}...")
            return True

        except Exception as e:
            print(f"ë¦¬ë·° ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def _normalize_url(self, url: str) -> str:
        """URL ì •ê·œí™” (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°)"""
        from urllib.parse import urlparse, urlunparse

        parsed = urlparse(url)
        # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°
        normalized = urlunparse((parsed.scheme, parsed.netloc, parsed.path, '', '', ''))
        return normalized

    def clear_expired_cache(self) -> int:
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬ (ë°°ì¹˜ ì‘ì—…ìš©)"""
        if not self.is_connected():
            return 0

        try:
            from datetime import datetime, timedelta

            # ê°€ì¥ ì˜¤ë˜ëœ TTL ê¸°ì¤€ìœ¼ë¡œ ì‚­ì œ (7ì¼)
            cutoff = (datetime.now() - timedelta(days=self.CACHE_TTL_DAYS_REVIEW)).isoformat()

            result = (
                self.client.table(self.TABLE_SCRAPE_CACHE)
                .delete()
                .lt("created_at", cutoff)
                .execute()
            )

            count = len(result.data) if result.data else 0
            print(f"ğŸ—‘ï¸ [Cache Cleanup] {count}ê°œ ì‚­ì œ")
            return count

        except Exception as e:
            print(f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return 0

    # --- í†µê³„ ---

    def get_stats(self) -> Dict[str, int]:
        """í†µê³„ ì¡°íšŒ"""
        if not self.is_connected():
            return {}

        try:
            keywords_count = len(self.client.table(self.TABLE_KEYWORDS).select("id", count="exact").execute().data or [])
            analyses_count = len(self.client.table(self.TABLE_ANALYSES).select("id", count="exact").execute().data or [])
            reports_count = len(self.client.table(self.TABLE_REPORTS).select("id", count="exact").execute().data or [])

            return {
                "keywords": keywords_count,
                "analyses": analyses_count,
                "reports": reports_count
            }
        except Exception:
            return {}


# --- Mock í´ë¼ì´ì–¸íŠ¸ (í…ŒìŠ¤íŠ¸ìš©) ---
class MockSupabaseClient(SupabaseClient):
    """í…ŒìŠ¤íŠ¸ìš© Mock í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self):
        super().__init__()
        self._initialized = True
        self._keywords: List[Dict] = []
        self._analyses: List[Dict] = []
        self._reports: List[Dict] = []

    def initialize(self) -> bool:
        return True

    def is_connected(self) -> bool:
        return True

    def save_keywords(self, keywords: List[KeywordRecord]) -> bool:
        for kw in keywords:
            record = asdict(kw)
            record["created_at"] = datetime.now().isoformat()
            self._keywords.append(record)
        return True

    def get_keywords(self, category: str = None, limit: int = 100) -> List[Dict]:
        data = self._keywords
        if category:
            data = [d for d in data if d.get("category") == category]
        return sorted(data, key=lambda x: x.get("opportunity_score", 0), reverse=True)[:limit]

    def save_analysis(self, analysis: AnalysisRecord) -> bool:
        record = asdict(analysis)
        record["created_at"] = datetime.now().isoformat()
        self._analyses.append(record)
        return True

    def get_analyses(self, product_name: str = None, limit: int = 50) -> List[Dict]:
        data = self._analyses
        if product_name:
            data = [d for d in data if product_name.lower() in d.get("product_name", "").lower()]
        return data[:limit]


# --- íŒ©í† ë¦¬ ---
def get_supabase_client(use_mock: bool = False) -> SupabaseClient:
    """Supabase í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    if use_mock:
        return MockSupabaseClient()

    client = SupabaseClient()
    client.initialize()
    return client


# --- í…ŒìŠ¤íŠ¸ ---
if __name__ == "__main__":
    print("="*50)
    print("ğŸ—„ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸")
    print("="*50)

    # Mock í´ë¼ì´ì–¸íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
    client = get_supabase_client(use_mock=True)

    print(f"\nì—°ê²° ìƒíƒœ: {'âœ… ì—°ê²°ë¨' if client.is_connected() else 'âŒ ë¯¸ì—°ê²°'}")

    # í‚¤ì›Œë“œ ì €ì¥ í…ŒìŠ¤íŠ¸
    test_keywords = [
        KeywordRecord(
            keyword="ìº í•‘ì˜ì",
            monthly_search_volume=45000,
            total_products=25000,
            competition_rate=0.56,
            opportunity_score=8.0,
            category="ìº í•‘/ë ˆì €"
        ),
        KeywordRecord(
            keyword="ì´ˆê²½ëŸ‰ ìº í•‘ì˜ì",
            monthly_search_volume=8500,
            total_products=3200,
            competition_rate=0.38,
            opportunity_score=17.7,
            category="ìº í•‘/ë ˆì €"
        ),
    ]

    print("\n[í‚¤ì›Œë“œ ì €ì¥]")
    if client.save_keywords(test_keywords):
        print("  âœ… ì €ì¥ ì„±ê³µ")
    else:
        print("  âŒ ì €ì¥ ì‹¤íŒ¨")

    print("\n[í‚¤ì›Œë“œ ì¡°íšŒ]")
    keywords = client.get_keywords(category="ìº í•‘/ë ˆì €")
    for kw in keywords:
        print(f"  - {kw['keyword']}: ê²€ìƒ‰ëŸ‰ {kw['monthly_search_volume']:,}")

    # ë¶„ì„ ê²°ê³¼ ì €ì¥ í…ŒìŠ¤íŠ¸
    test_analysis = AnalysisRecord(
        report_id="test_001",
        product_name="ì´ˆê²½ëŸ‰ ìº í•‘ ì˜ì",
        category="ìº í•‘/ë ˆì €",
        margin_percent=-28.0,
        total_score=35.5,
        is_viable=False,
        recommendation="âŒ ìˆ˜ìµì„± ë¶€ì¡±"
    )

    print("\n[ë¶„ì„ ê²°ê³¼ ì €ì¥]")
    if client.save_analysis(test_analysis):
        print("  âœ… ì €ì¥ ì„±ê³µ")

    print("\n" + "="*50)
    print("âœ… Supabase í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ ì¤€ë¹„ ì™„ë£Œ")
    print("   ì‹¤ì œ ì‚¬ìš© ì‹œ SUPABASE_URL, SUPABASE_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”")
    print("="*50)
